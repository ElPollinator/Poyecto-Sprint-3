{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "\u00a1Hola, Carlos!\n\nMi nombre es Tonatiuh Cruz. Me complace revisar tu proyecto hoy.\n\nAl identificar cualquier error inicialmente, simplemente los destacar\u00e9. Te animo a localizar y abordar los problemas de forma independiente como parte de tu preparaci\u00f3n para un rol como data-analyst. En un entorno profesional, tu l\u00edder de equipo seguir\u00eda un enfoque similar. Si encuentras la tarea desafiante, proporcionar\u00e9 una pista m\u00e1s espec\u00edfica en la pr\u00f3xima iteraci\u00f3n.\n\nEncontrar\u00e1s mis comentarios a continuaci\u00f3n - **por favor no los muevas, modifiques o elimines**.\n\nPuedes encontrar mis comentarios en cajas verdes, amarillas o rojas como esta:\n\n<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\n\u00c9xito. Todo est\u00e1 hecho correctamente.\n</div>\n\n<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nObservaciones. Algunas recomendaciones.\n</div>\n\n<div class=\"alert alert-block alert-danger\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nNecesita correcci\u00f3n. El bloque requiere algunas correcciones. El trabajo no puede ser aceptado con comentarios en rojo.\n</div>\n\nPuedes responderme utilizando esto:\n\n<div class=\"alert alert-block alert-info\">\n<b>Respuesta del estudiante.</b> <a class=\"tocSkip\"></a>\n</div>"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Resumen de la revisi\u00f3n 1</b> <a class=\"tocSkip\"></a>\n\nHola, Carlos! Has hecho un excelente trabajo al realizar el proyecto, usaste diferentes herramientas apredidas en el curso.Ya solamente te dejo algunos comentarios para terminar de complementar los an\u00e1lisis. \n\nSigue con el excelente trabajo!\n</div>"}, {"cell_type": "markdown", "metadata": {"id": "E0vqbgi9ay0H"}, "source": "# D\u00e9jame escuchar m\u00fasica"}, {"cell_type": "markdown", "metadata": {"id": "fhq_eyov_Zcs"}, "source": "# Contenido <a id='back'></a>\n\n* [Introducci\u00f3n](#intro)\n* [Etapa 1. Descripci\u00f3n de los datos](#data_review)\n    * [Conclusiones](#data_review_conclusions)\n* [Etapa 2. Preprocesamiento de datos](#data_preprocessing)\n    * [2.1 Estilo del encabezado](#header_style)\n    * [2.2 Valores ausentes](#missing_values)\n    * [2.3 Duplicados](#duplicates)\n    * [2.4 Conclusiones](#data_preprocessing_conclusions)\n* [Etapa 3. Prueba de hip\u00f3tesis](#hypothesis)\n    * [3.1 Hip\u00f3tesis 1: actividad de los usuarios y las usuarias en las dos ciudades](#activity)\n* [Conclusiones](#end)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-warning\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nLa tabla de contenidos est\u00e1 bien estructurada, pero ser\u00eda \u00fatil si estuviera enlazada a las secciones correspondientes, de manera que al hacer clic se pueda acceder directamente a cada una. Esto facilitar\u00eda la navegaci\u00f3n."}, {"cell_type": "markdown", "metadata": {"id": "VUC88oWjTJw2"}, "source": "## Introducci\u00f3n <a id='intro'></a>\nComo analista de datos, tu trabajo consiste en analizar datos para extraer informaci\u00f3n valiosa de ellos y tomar decisiones en consecuencia. Esto implica pasar por diferentes etapas, como la descripci\u00f3n general de los datos, el preprocesamiento y la prueba de hip\u00f3tesis.\n\nSiempre que investiguemos, necesitamos formular hip\u00f3tesis que despu\u00e9s podamos probar. A veces, aceptaremos estas hip\u00f3tesis; otras veces, las rechazaremos. Para tomar las decisiones adecuadas, una empresa debe ser capaz de entender si est\u00e1 haciendo las suposiciones correctas.\n\nEn este proyecto, comparar\u00e1s las preferencias musicales de las ciudades de Springfield y Shelbyville. Estudiar\u00e1s datos reales de m\u00fasica online para probar la hip\u00f3tesis que planteamos a continuaci\u00f3n y comparar\u00e1s el comportamiento de los usuarios de estas dos ciudades.\n\n### Objetivo:\nProbar la hip\u00f3tesis:\n1. La actividad de los usuarios difiere seg\u00fan el d\u00eda de la semana y dependiendo de la ciudad.\n\n\n### Etapas\nLos datos del comportamiento de los usuarios se almacenan en el archivo `/datasets/music_project_en.csv`. No hay informaci\u00f3n sobre la calidad de los datos, as\u00ed que necesitar\u00e1s examinarlos antes de probar la hip\u00f3tesis.\n\nPrimero, debes evaluar la calidad de los datos y ver si los problemas son significativos. M\u00e1s tarde, durante el preprocesamiento de datos, deber\u00e1s abordar los problemas m\u00e1s cr\u00edticos.\n\nTu proyecto contar\u00e1 con estas tres etapas:\n 1. Descripci\u00f3n de los datos.\n 2. Preprocesamiento de los datos.\n 3. Prueba de la hip\u00f3tesis.\n\n\n\n\n\n\n"}, {"cell_type": "markdown", "metadata": {"id": "hDt6pg-Rw-1U"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "Ml1hmfXC_Zcs"}, "source": "## Etapa 1. Descripci\u00f3n de los datos <a id='data_review'></a>\n\nAbre los datos y exam\u00ednalos."}, {"cell_type": "markdown", "metadata": {"id": "57eAOGIz_Zcs"}, "source": "Etapa 1.1. Necesitar\u00e1s `pandas`, as\u00ed que imp\u00f3rtalo."}, {"cell_type": "code", "execution_count": 9, "metadata": {"id": "AXN7PHPN_Zcs", "trusted": true}, "outputs": [], "source": "# Importa pandas\nimport pandas as pd"}, {"cell_type": "markdown", "metadata": {"id": "SG23P8tt_Zcs"}, "source": "Etapa 1.2. Lee el archivo `music_project_en.csv` de la carpeta `/datasets/` y gu\u00e1rdalo en la variable `df`:"}, {"cell_type": "code", "execution_count": 10, "metadata": {"id": "fFVu7vqh_Zct", "trusted": true}, "outputs": [], "source": "# Lee el archivo y almac\u00e9nalo en df\ndf=pd.read_csv('/datasets/music_project_en.csv')"}, {"cell_type": "markdown", "metadata": {"id": "rDoOMd3uTqnZ"}, "source": "Etapa 1.3. Muestra las 10 primeras filas de la tabla:"}, {"cell_type": "code", "execution_count": 11, "metadata": {"id": "oWTVX3gW_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "     userID                        Track            artist   genre  \\\n0  FFB692EC            Kamigata To Boots  The Mass Missile    rock   \n1  55204538  Delayed Because of Accident  Andreas R\u00f6nnberg    rock   \n2    20EC38            Funicul\u00ec funicul\u00e0       Mario Lanza     pop   \n3  A3DD03C9        Dragons in the Sunset        Fire + Ice    folk   \n4  E2DC1FAE                  Soul People        Space Echo   dance   \n5  842029A1                       Chains          Obladaet  rusrap   \n6  4CB90AA5                         True      Roman Messer   dance   \n7  F03E1C1F             Feeling This Way   Polina Griffith   dance   \n8  8FA1D3BE                     L\u2019estate       Julia Dalia  ruspop   \n9  E772D5C0                    Pessimist               NaN   dance   \n\n        City        time        Day  \n0  Shelbyville  20:28:33  Wednesday  \n1  Springfield  14:07:09     Friday  \n2  Shelbyville  20:58:07  Wednesday  \n3  Shelbyville  08:37:09     Monday  \n4  Springfield  08:34:34     Monday  \n5  Shelbyville  13:09:41     Friday  \n6  Springfield  13:00:07  Wednesday  \n7  Springfield  20:47:49  Wednesday  \n8  Springfield  09:17:40     Friday  \n9  Shelbyville  21:20:49  Wednesday  \n"}], "source": "# Obt\u00e9n las 10 primeras filas de la tabla df\nprint(df.head(10))"}, {"cell_type": "markdown", "metadata": {"id": "EO73Kwic_Zct"}, "source": "Etapa 1.4. Obt\u00e9n la informaci\u00f3n general sobre la tabla con el m\u00e9todo info()."}, {"cell_type": "code", "execution_count": 12, "metadata": {"id": "DSf2kIb-_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 65079 entries, 0 to 65078\nData columns (total 7 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0     userID  65079 non-null  object\n 1   Track     63736 non-null  object\n 2   artist    57512 non-null  object\n 3   genre     63881 non-null  object\n 4     City    65079 non-null  object\n 5   time      65079 non-null  object\n 6   Day       65079 non-null  object\ndtypes: object(7)\nmemory usage: 3.5+ MB\n"}], "source": "# Obt\u00e9n la informaci\u00f3n general sobre nuestros datos\ndf.info()"}, {"cell_type": "markdown", "metadata": {"id": "TaQ2Iwbr_Zct"}, "source": "Estas son nuestras observaciones sobre la tabla. Contiene siete columnas que almacenan los mismos tipos de datos: `object`.\n\nSeg\u00fan la documentaci\u00f3n:\n- `' userID'`: identificador del usuario;\n- `'Track'`: t\u00edtulo de la canci\u00f3n;\n- `'artist'`: nombre del artista;\n- `'genre'`: g\u00e9nero de la canci\u00f3n;\n- `'City'`: ciudad del usuario;\n- `'time'`: la hora exacta en la que se reprodujo la canci\u00f3n;\n- `'Day'`: d\u00eda de la semana.\n\nPodemos ver tres problemas con el estilo en los encabezados de la tabla:\n1. Algunos encabezados est\u00e1n en may\u00fasculas, otros en min\u00fasculas.\n2. Hay espacios en algunos encabezados.\n3. `Detecta el tercer problema por tu cuenta y descr\u00edbelo aqu\u00ed`: Hay valores nulos.\n\n\n"}, {"cell_type": "markdown", "metadata": {"id": "MCB6-dXG_Zct"}, "source": "### Escribe algunas observaciones por tu parte. Contesta a las siguientes preguntas: <a id='data_review_conclusions'></a>\n\n`1.   \u00bfQu\u00e9 tipo de datos hay en las filas? \u00bfC\u00f3mo podemos saber qu\u00e9 almacenan las columnas?`\n\n`2.   \u00bfHay suficientes datos para proporcionar respuestas a nuestra hip\u00f3tesis o necesitamos m\u00e1s informaci\u00f3n?`\n\n`3.   \u00bfNotaste alg\u00fan problema en los datos, como valores ausentes, duplicados o tipos de datos incorrectos?`"}, {"cell_type": "markdown", "metadata": {"id": "emewmQcy3m_F"}, "source": "Escribe aqu\u00ed tus respuestas:\n\n1. Todos son strings, podemos saber qu\u00e9 almacenan gracias a una impresi\u00f3n de las primeras filas con head() o mediante sample() \n\n2. Deber\u00edan ser suficientes, si bien hay valores nulos, contamos con m\u00e1s del 88% de los datos\n\n3. Por ahora s\u00f3lo valores ausentes"}, {"cell_type": "markdown", "metadata": {"id": "3eL__vcwViOi"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "SjYF6Ub9_Zct"}, "source": "## Etapa 2. Preprocesamiento de los datos <a id='data_preprocessing'></a>\n\nTu objetivo aqu\u00ed es preparar los datos para analizarlos.\nEl primer paso es resolver los problemas con los encabezados. Despu\u00e9s podemos avanzar a los valores ausentes y duplicados. \u00a1Empecemos!\n\nVamos a corregir el formato en los encabezados de la tabla.\n"}, {"cell_type": "markdown", "metadata": {"id": "dIaKXr29_Zct"}, "source": "### Estilo del encabezado <a id='header_style'></a>\nEtapa 2.1. Muestra los encabezados de la tabla (los nombres de las columnas):"}, {"cell_type": "code", "execution_count": 13, "metadata": {"id": "oKOTdF_Q_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['  userID', 'Track', 'artist', 'genre', '  City  ', 'time', 'Day'], dtype='object')\n"}], "source": "# Muestra los nombres de las columnas\nprint(df.columns)"}, {"cell_type": "code", "execution_count": null, "metadata": {"id": "Un4tf8yr-GN2", "trusted": true}, "outputs": [], "source": ""}, {"cell_type": "markdown", "metadata": {"id": "zj5534cv_Zct"}, "source": "Vamos cambiar los encabezados de la tabla siguiendo las reglas estil\u00edsticas convencionales:\n*   Todos los caracteres deben ser min\u00fasculas.\n*   Elimina los espacios.\n*   Si el nombre tiene varias palabras, utiliza snake_case.\n"}, {"cell_type": "markdown", "metadata": {"id": "Xu0zkfe5zNJe"}, "source": "Anteriormente, aprendiste una forma autom\u00e1tica de cambiar el nombre de las columnas. Vamos a aplicarla ahora.\n\nEtapa 2.2. Utiliza el bucle for para iterar sobre los nombres de las columnas y poner todos los caracteres en min\u00fasculas. Cuando hayas terminado, vuelve a mostrar los encabezados de la tabla:"}, {"cell_type": "code", "execution_count": 14, "metadata": {"id": "6I_RwwMhzM4e", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['  userid', 'track', 'artist', 'genre', '  city  ', 'time', 'day'], dtype='object')\n"}], "source": "# Bucle en los encabezados que lo pone todo en min\u00fasculas\ncolumns_lowered=[]\nfor col in df.columns:\n    columns_lowered.append(col.lower())\n\ndf.columns=columns_lowered\n    \nprint(df.columns)"}, {"cell_type": "markdown", "metadata": {"id": "pweIRxjSzPYW"}, "source": "Etapa 2.3. Ahora, utilizando el mismo m\u00e9todo, elimina los espacios al principio y al final de los nombres de las columnas y muestra los nombres de las columnas de nuevo:"}, {"cell_type": "code", "execution_count": 15, "metadata": {"id": "vVQXbFyJzSYl", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['userid', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}], "source": "# Bucle en los encabezados que elimina los espacios\ncolumns_striped=[]\nfor col in df.columns:\n    columns_striped.append(col.strip())\n    \ndf.columns=columns_striped\n\nprint(df.columns)"}, {"cell_type": "markdown", "metadata": {"id": "yCb8MW1JzURd"}, "source": "Etapa 2.4. Necesitamos aplicar la regla de snake_case en la columna `userid`. Debe ser `user_id`. Cambia el nombre de esta columna y muestra los nombres de todas las columnas cuando hayas terminado."}, {"cell_type": "code", "execution_count": 16, "metadata": {"id": "ISlFqs5y_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}], "source": "# Cambia el nombre de la columna \"userid\"\n\ndf.rename(columns={'userid': 'user_id'}, inplace=True)\n\nprint(df.columns)\n"}, {"cell_type": "markdown", "metadata": {"id": "1dqbh00J_Zct"}, "source": "Etapa 2.5. Comprueba el resultado. Muestra los encabezados una vez m\u00e1s:"}, {"cell_type": "code", "execution_count": 17, "metadata": {"id": "d4NOAmTW_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Index(['user_id', 'track', 'artist', 'genre', 'city', 'time', 'day'], dtype='object')\n"}], "source": "# Comprueba el resultado: lista de encabezados\nprint(df.columns)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nMuy buen trabajo! Ajustaste todos los elementos."}, {"cell_type": "markdown", "metadata": {"id": "xYJk6ksJVpOl"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "5ISfbcfY_Zct"}, "source": "### Valores ausentes <a id='missing_values'></a>\n Etapa 2.5. Primero, encuentra el n\u00famero de valores ausentes en la tabla. Debes utilizar dos m\u00e9todos para obtener el n\u00famero de valores ausentes."}, {"cell_type": "code", "execution_count": 18, "metadata": {"id": "RskX29qr_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "user_id       0\ntrack      1343\nartist     7567\ngenre      1198\ncity          0\ntime          0\nday           0\ndtype: int64\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 65079 entries, 0 to 65078\nData columns (total 7 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   user_id  65079 non-null  object\n 1   track    63736 non-null  object\n 2   artist   57512 non-null  object\n 3   genre    63881 non-null  object\n 4   city     65079 non-null  object\n 5   time     65079 non-null  object\n 6   day      65079 non-null  object\ndtypes: object(7)\nmemory usage: 3.5+ MB\nNone\n"}], "source": "# Calcula el n\u00famero de valores ausentes\nprint(df.isna().sum())\nprint()\nprint(df.info())"}, {"cell_type": "markdown", "metadata": {"id": "qubhgnlO_Zct"}, "source": "No todos los valores ausentes afectan de la misma forma a la investigaci\u00f3n. Por ejemplo, los valores ausentes en 'track' y 'artist' no son cruciales para el an\u00e1lisis, ya que estos datos son m\u00e1s descriptivos que anal\u00edticos. Por eso, puedes reemplazarlos directamente con un valor predeterminado como el string 'unknown' (desconocido)."}, {"cell_type": "markdown", "metadata": {"id": "gzJd_997466T"}, "source": "En cambio, los valores ausentes en 'genre' s\u00ed pueden influir en la comparaci\u00f3n entre las preferencias musicales de Springfield y Shelbyville. En un escenario real, lo ideal ser\u00eda investigar por qu\u00e9 faltan estos datos e intentar recuperarlos. Pero en este proyecto no tenemos esa posibilidad, as\u00ed que deber\u00e1s rellenar esos valores con un valor predeterminado.\n"}, {"cell_type": "markdown", "metadata": {"id": "5IzUHGWE5Els"}, "source": "Como vimos anteriormente en las lecciones, la mejor manera de hacerlo es crear una lista con los nombres de las columnas que necesitan reemplazarse.  Luego, utilizar esta lista para iterar sobre cada columna y realizar el reemplazo correspondiente."}, {"cell_type": "markdown", "metadata": {"id": "fSv2laPA_Zct"}, "source": "Etapa 2.6. Sustituye los valores ausentes en las columnas `'track'`, `'artist'` y `'genre'` con el string `'unknown'`.\n\n1. Crea una lista llamada columns_to_replace que contenga los nombres de las columnas 'track', 'artist' y 'genre'.\n\n2. Usa un bucle for para iterar sobre cada columna en columns_to_replace.\n\n3. Dentro del bucle, sustituye los valores ausentes en cada columna con el string `'unknown'`."}, {"cell_type": "code", "execution_count": 19, "metadata": {"id": "KplB5qWs_Zct", "trusted": true}, "outputs": [], "source": "# Bucle en los encabezados reemplazando los valores ausentes con 'unknown'\ncolumns_to_replace=[\"track\",\"artist\",\"genre\"]\n\nfor col in columns_to_replace:\n    df[col]=df[col].fillna(\"unknown\")"}, {"cell_type": "markdown", "metadata": {"id": "Ilsm-MZo_Zct"}, "source": "Etapa 2.7. Ahora comprueba el resultado para asegurarte de que no falten valores ausentes por reemplazar en el conjunto de datos. Para ello, cuenta los valores ausentes una vez m\u00e1s."}, {"cell_type": "code", "execution_count": 20, "metadata": {"id": "Tq4nYRX4_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "user_id    0\ntrack      0\nartist     0\ngenre      0\ncity       0\ntime       0\nday        0\ndtype: int64\n"}], "source": "# Cuenta los valores ausentes\n\nprint(df.isna().sum())"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nMuy buen trabajo! Ajustaste todos los elementos con valores ausentes y los cambiaste con una etiqueta \"unkown\" que nos permite identificarlos</div>"}, {"cell_type": "markdown", "metadata": {"id": "74ZIBmq9VrsK"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "BWKRtBJ3_Zct"}, "source": "### Duplicados <a id='duplicates'></a>\nEtapa 2.8. Encuentra el n\u00famero de duplicados expl\u00edcitos en la tabla. Una vez m\u00e1s, debes aplicar dos m\u00e9todos para obtener la cantidad de duplicados expl\u00edcitos."}, {"cell_type": "code", "execution_count": 21, "metadata": {"id": "36eES_S0_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Valores duplicados:  3826\n"}], "source": "# Cuenta los duplicados expl\u00edcitos\nprint(\"Valores duplicados: \",df.duplicated().sum())\n"}, {"cell_type": "markdown", "metadata": {"id": "Ot25h6XR_Zct"}, "source": "Etapa 2.9. Ahora, elimina todos los duplicados. Para ello, llama al m\u00e9todo que hace exactamente esto."}, {"cell_type": "code", "execution_count": 22, "metadata": {"id": "exFHq6tt_Zct", "trusted": true}, "outputs": [], "source": "# Elimina los duplicados expl\u00edcitos\ndf.drop_duplicates(inplace=True)"}, {"cell_type": "markdown", "metadata": {"id": "Im2YwBEG_Zct"}, "source": "Etapa 2.10. Comprobemos ahora si conseguimos eliminar todos los duplicados. Cuenta los duplicados expl\u00edcitos una vez m\u00e1s para asegurarte de haberlos eliminado todos:"}, {"cell_type": "code", "execution_count": 23, "metadata": {"id": "-8PuNWQ0_Zct", "trusted": true}, "outputs": [{"data": {"text/plain": "0"}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": "# Comprueba de nuevo si hay duplicados\ndf.duplicated().sum()"}, {"cell_type": "markdown", "metadata": {"id": "QlFBsxAr_Zct"}, "source": "Ahora queremos deshacernos de los duplicados impl\u00edcitos en la columna `genre`. Por ejemplo, el nombre de un g\u00e9nero se puede escribir de varias formas. Dichos errores tambi\u00e9n pueden afectar al resultado."}, {"cell_type": "markdown", "metadata": {"id": "eSjWwsOh_Zct"}, "source": "Etapa 2.11. Primero debemos mostrar una lista de nombres de g\u00e9neros \u00fanicos, por orden alfab\u00e9tico. Para ello:\n1. Extrae la columna `genre` del DataFrame.\n2. Llama al m\u00e9todo que devolver\u00e1 todos los valores \u00fanicos en la columna extra\u00edda.\n"}, {"cell_type": "code", "execution_count": 24, "metadata": {"id": "JIUcqzZN_Zct", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n 'unknown' 'alternative' 'children' 'rnb' 'hip' 'jazz' 'postrock' 'latin'\n 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental' 'rusrock'\n 'dnb' 't\u00fcrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n 'disco' 'religious' 'hiphop' 'drum' 'extrememetal' 't\u00fcrk\u00e7e'\n 'experimental' 'easy' 'metalcore' 'modern' 'argentinetango' 'old' 'swing'\n 'breaks' 'eurofolk' 'stonerrock' 'industrial' 'funk' 'middle' 'vari\u00e9t\u00e9'\n 'other' 'adult' 'christian' 'thrash' 'gothic' 'international' 'muslim'\n 'relax' 'schlager' 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage'\n 'specialty' 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power'\n 'death' 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european'\n 'tech' 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera'\n 'celtic' 'tradjazz' 'acoustic' 'epicmetal' 'hip-hop' 'historisch'\n 'downbeat' 'downtempo' 'africa' 'audiobook' 'jewish' 's\u00e4ngerportrait'\n 'deutschrock' 'eastern' 'action' 'future' 'electropop' 'folklore'\n 'bollywood' 'marschmusik' 'rnr' 'karaoke' 'indian' 'rancheras'\n 'afrikaans' 'rhythm' 'sound' 'deutschspr' 'trip' 'lovers' 'choral'\n 'dancepop' 'retro' 'smooth' 'mexican' 'brazilian' '\u00ef\u00ee\u00ef' 'mood' 'surf'\n 'gangsta' 'inspirational' 'idm' 'ethnic' 'bluegrass' 'broadway'\n 'animated' 'americana' 'karadeniz' 'rockabilly' 'colombian' 'self' 'hop'\n 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport' 'ragga' 'traditional'\n 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop' 'glitch' 'documentary'\n 'oceania' 'popeurodance' 'dark' 'vi' 'grunge' 'hardstyle' 'samba'\n 'garage' 'art' 'folktronica' 'entehno' 'mediterranean' 'chamber' 'cuban'\n 'taraftar' 'gypsy' 'hardtechno' 'shoegazing' 'bossa' 'latino' 'worldbeat'\n 'malaysian' 'baile' 'ghazal' 'arabic' 'popelectronic' 'acid' 'kayokyoku'\n 'neoklassik' 'tribal' 'tanzorchester' 'native' 'independent' 'cantautori'\n 'handsup' 'punjabi' 'synthpop' 'rave' 'franz\u00f6sisch' 'quebecois' 'speech'\n 'soulful' 'jam' 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow'\n 'jungle' 'indipop' 'ax\u00e9' 'fado' 'showtunes' 'arena' 'irish' 'mandopop'\n 'forr\u00f3' 'dirty' 'regional']\n"}], "source": "# Inspecciona los nombres de g\u00e9neros \u00fanicos\nprint(df[\"genre\"].unique())"}, {"cell_type": "markdown", "metadata": {"id": "qej-Qmuo_Zct"}, "source": "Vamos a examinar la lista para identificar **duplicados impl\u00edcitos** del g\u00e9nero `hiphop`, es decir, nombres mal escritos o variantes que hacen referencia al mismo g\u00e9nero musical.\n\nAlgunos de los duplicados que encontrar\u00e1s son:\n\n* `hip`  \n* `hop`  \n* `hip-hop`  \n\nPara solucionarlo, vamos a crear una funci\u00f3n llamada `replace_wrong_genres()` que tendr\u00e1 dos par\u00e1metros:\n\n* `wrong_genres`: una lista con todos los valores que deben ser reemplazados.  \n* `correct_genre`: un string que se utilizar\u00e1 como valor de reemplazo.\n\nEl objetivo de esta funci\u00f3n es **corregir los valores en la columna `'genre'` del DataFrame `df`**, reemplazando cada valor de la lista `wrong_genres` por `correct_genre`."}, {"cell_type": "markdown", "metadata": {"id": "7kmujhjP_bIl"}, "source": "Etapa 2.12.\n1. Define una funci\u00f3n llamada `replace_wrong_genres()` que reciba dos par\u00e1metros: `wrong_genres` y `correct_genre`.\n\n2. Dentro de la funci\u00f3n, utiliza un bucle `for` para iterar sobre cada valor en la lista `wrong_genres`.\n\n3. En cada iteraci\u00f3n, accede a la columna `'genre'` del DataFrame `df` y utiliza el m\u00e9todo `.replace()` para sustituir el valor incorrecto por `correct_genre`.\n\n4. Llama a la funci\u00f3n y pasa como argumentos:\n   - Una lista con los duplicados impl\u00edcitos: `['hip', 'hop', 'hip-hop']`\n   - El string de reemplazo: `'hiphop'`"}, {"cell_type": "code", "execution_count": 25, "metadata": {"id": "ErNDkmns_Zct", "trusted": true}, "outputs": [], "source": "# Funci\u00f3n para reemplazar los duplicados impl\u00edcitos\nwrong_genres=[\"hip\",\"hop\",\"hip-hop\"]\n\ndef replace_wrong_genres(df, wrong_genres, correct_genre):\n    df[\"genre\"] = df[\"genre\"].replace(wrong_genres, correct_genre)"}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nExcelente trabajo con la funci\u00f3n. Con esto nos permitira reemplazar los registros duplicados con los valores que coloquemos dentro del argumento de la funci\u00f3n</div>"}, {"cell_type": "markdown", "metadata": {"id": "aDoBJxbA_Zct"}, "source": "Etapa 2.13. Ahora, llama a `replace_wrong_genres()` y p\u00e1sale estos argumentos para que retire los duplicados impl\u00edcitos (`hip`, `hop` y `hip-hop`) y los sustituya por `hiphop`:"}, {"cell_type": "code", "execution_count": 26, "metadata": {"id": "YN5i2hpmSo09", "trusted": true}, "outputs": [], "source": "# Elimina los duplicados impl\u00edcitos\nwrong_genres = [\"hip\", \"hop\", \"hip-hop\"]\nreplace_wrong_genres(df, wrong_genres, \"hiphop\")\n"}, {"cell_type": "markdown", "metadata": {"id": "zQKF16_RG15m"}, "source": "Etapa 2.14. Aseg\u00farate de que los nombres duplicados se hayan eliminado. Muestra la lista de valores \u00fanicos de la columna `'genre'` una vez m\u00e1s:"}, {"cell_type": "code", "execution_count": 27, "metadata": {"id": "wvixALnFG15m", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['rock' 'pop' 'folk' 'dance' 'rusrap' 'ruspop' 'world' 'electronic'\n 'unknown' 'alternative' 'children' 'rnb' 'hiphop' 'jazz' 'postrock'\n 'latin' 'classical' 'metal' 'reggae' 'triphop' 'blues' 'instrumental'\n 'rusrock' 'dnb' 't\u00fcrk' 'post' 'country' 'psychedelic' 'conjazz' 'indie'\n 'posthardcore' 'local' 'avantgarde' 'punk' 'videogame' 'techno' 'house'\n 'christmas' 'melodic' 'caucasian' 'reggaeton' 'soundtrack' 'singer' 'ska'\n 'salsa' 'ambient' 'film' 'western' 'rap' 'beats' \"hard'n'heavy\"\n 'progmetal' 'minimal' 'tropical' 'contemporary' 'new' 'soul' 'holiday'\n 'german' 'jpop' 'spiritual' 'urban' 'gospel' 'nujazz' 'folkmetal'\n 'trance' 'miscellaneous' 'anime' 'hardcore' 'progressive' 'korean'\n 'numetal' 'vocal' 'estrada' 'tango' 'loungeelectronic' 'classicmetal'\n 'dubstep' 'club' 'deep' 'southern' 'black' 'folkrock' 'fitness' 'french'\n 'disco' 'religious' 'drum' 'extrememetal' 't\u00fcrk\u00e7e' 'experimental' 'easy'\n 'metalcore' 'modern' 'argentinetango' 'old' 'swing' 'breaks' 'eurofolk'\n 'stonerrock' 'industrial' 'funk' 'middle' 'vari\u00e9t\u00e9' 'other' 'adult'\n 'christian' 'thrash' 'gothic' 'international' 'muslim' 'relax' 'schlager'\n 'caribbean' 'nu' 'breakbeat' 'comedy' 'chill' 'newage' 'specialty'\n 'uzbek' 'k-pop' 'balkan' 'chinese' 'meditative' 'dub' 'power' 'death'\n 'grime' 'arabesk' 'romance' 'flamenco' 'leftfield' 'european' 'tech'\n 'newwave' 'dancehall' 'mpb' 'piano' 'top' 'bigroom' 'opera' 'celtic'\n 'tradjazz' 'acoustic' 'epicmetal' 'historisch' 'downbeat' 'downtempo'\n 'africa' 'audiobook' 'jewish' 's\u00e4ngerportrait' 'deutschrock' 'eastern'\n 'action' 'future' 'electropop' 'folklore' 'bollywood' 'marschmusik' 'rnr'\n 'karaoke' 'indian' 'rancheras' 'afrikaans' 'rhythm' 'sound' 'deutschspr'\n 'trip' 'lovers' 'choral' 'dancepop' 'retro' 'smooth' 'mexican'\n 'brazilian' '\u00ef\u00ee\u00ef' 'mood' 'surf' 'gangsta' 'inspirational' 'idm' 'ethnic'\n 'bluegrass' 'broadway' 'animated' 'americana' 'karadeniz' 'rockabilly'\n 'colombian' 'self' 'sertanejo' 'japanese' 'canzone' 'lounge' 'sport'\n 'ragga' 'traditional' 'gitarre' 'frankreich' 'emo' 'laiko' 'cantopop'\n 'glitch' 'documentary' 'oceania' 'popeurodance' 'dark' 'vi' 'grunge'\n 'hardstyle' 'samba' 'garage' 'art' 'folktronica' 'entehno'\n 'mediterranean' 'chamber' 'cuban' 'taraftar' 'gypsy' 'hardtechno'\n 'shoegazing' 'bossa' 'latino' 'worldbeat' 'malaysian' 'baile' 'ghazal'\n 'arabic' 'popelectronic' 'acid' 'kayokyoku' 'neoklassik' 'tribal'\n 'tanzorchester' 'native' 'independent' 'cantautori' 'handsup' 'punjabi'\n 'synthpop' 'rave' 'franz\u00f6sisch' 'quebecois' 'speech' 'soulful' 'jam'\n 'ram' 'horror' 'orchestral' 'neue' 'roots' 'slow' 'jungle' 'indipop'\n 'ax\u00e9' 'fado' 'showtunes' 'arena' 'irish' 'mandopop' 'forr\u00f3' 'dirty'\n 'regional']\n"}], "source": "# Comprueba de nuevo los duplicados impl\u00edcitos\nprint(df[\"genre\"].unique())"}, {"cell_type": "markdown", "metadata": {"id": "ALgNbvF3VtPA"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "jz6a9-7HQUDd"}, "source": "### Observaciones <a id='data_preprocessing_conclusions'></a>\n\n`Redacta un breve resumen de lo que descubriste al analizar los datos. Tu respuesta debe identificar los problemas detectados, explicar c\u00f3mo los resolviste y describir c\u00f3mo esas acciones mejoran la calidad del an\u00e1lisis.`"}, {"cell_type": "markdown", "metadata": {"id": "lN8zFHxhAF5O"}, "source": "Etapa 2.14. Descr\u00edbelo aqu\u00ed.\n\nTarjeta de errores detectados:\n\n-Los nombres de las columnas var\u00edan en cuanto a formato: May\u00fasculas, min\u00fasculas y espacios. Esto se ha solucionado mediante la homologaci\u00f3n de los formatos (todo a min\u00fasculas y sin espacios)\n\n-Se han detectado tanto valores nulos como duplicados expl\u00edcitos en la informaci\u00f3n. Estos se han corregido mediante sustituci\u00f3n y eliminaci\u00f3n, respectivamente.\n\n-As\u00ed como los valores duplicados expl\u00edcitos, tambi\u00e9n se identificaron valores duplicados impl\u00edcitos que se corrigieron mediante la homologaci\u00f3n del nombre correcto\n\n\nAsegurar la correcta informaci\u00f3n nos garantiza trabajar con un dataframe mejor elaborado.\n"}, {"cell_type": "markdown", "metadata": {"id": "eK1es74rVujj"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "WttZHXH0SqKk"}, "source": "## Etapa 3. Prueba de la hip\u00f3tesis <a id='hypothesis'></a>"}, {"cell_type": "markdown", "metadata": {"id": "Im936VVi_Zcu"}, "source": "### Tarea: Comparar el comportamiento de los usuarios en las dos ciudades <a id='activity'></a>"}, {"cell_type": "markdown", "metadata": {"id": "nwt_MuaL_Zcu"}, "source": "La hip\u00f3tesis que queremos probar plantea que existen diferencias en la forma en que los usuarios de Springfield y Shelbyville consumen m\u00fasica.\nPara analizar esto, nos enfocaremos en los datos correspondientes a tres d\u00edas espec\u00edficos de la semana: lunes, mi\u00e9rcoles y viernes."}, {"cell_type": "markdown", "metadata": {"id": "8Dw_YMmT_Zcu"}, "source": "El an\u00e1lisis consistir\u00e1 en comparar la cantidad de canciones reproducidas por los usuarios de cada ciudad en esos d\u00edas. Esto nos permitir\u00e1 observar posibles patrones o diferencias en los h\u00e1bitos de consumo entre Springfield y Shelbyville.\n\nPara llevar a cabo este an\u00e1lisis, es importante seguir el enfoque de dividir-aplicar-combinar, del que ya hablamos en la lecci\u00f3n. En este caso:\n\n*  Dividir: separamos los datos en grupos seg\u00fan la ciudad.\n\n*  Aplicar: dentro de cada grupo, contamos cu\u00e1ntas canciones se reprodujeron.\n\n*  Combinar: reunimos los resultados en una estructura que nos permita comparar f\u00e1cilmente ambas ciudades."}, {"cell_type": "markdown", "metadata": {"id": "c0MoTnZcB-hW"}, "source": "Este procedimiento debe repetirse de forma independiente para cada uno de los tres d\u00edas seleccionados. El resultado final debe mostrar el n\u00famero de reproducciones por ciudad en cada uno de esos d\u00edas.\n\nUna posible forma de estructurar el c\u00f3digo ser\u00eda con la siguiente expresi\u00f3n:\n\n`df.groupby(by='...')['...'].method()`\n\nDeber\u00e1s completar los argumentos correspondientes para agrupar por ciudad y contar las canciones reproducidas. Este enfoque te dar\u00e1 una visi\u00f3n clara y comparativa del comportamiento de los usuarios en ambas ciudades."}, {"cell_type": "markdown", "metadata": {"id": "dgMGeLF2CMJv"}, "source": "Etapa 3.1. Cuenta cu\u00e1ntas canciones se reprodujeron en cada ciudad utilizando la columna 'track' como referencia."}, {"cell_type": "code", "execution_count": 28, "metadata": {"trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "['Wednesday' 'Friday' 'Monday']\n"}], "source": "print(df[\"day\"].unique())"}, {"cell_type": "code", "execution_count": 29, "metadata": {"id": "0_Qs96oh_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Tracks de Monday: city\nShelbyville     5614\nSpringfield    15740\nName: track, dtype: int64\n\nTracks de Wednesday: city\nShelbyville     7003\nSpringfield    11056\nName: track, dtype: int64\n\nTracks de Friday: city\nShelbyville     5895\nSpringfield    15945\nName: track, dtype: int64\n\nNone\n"}], "source": "# Cuenta las canciones reproducidas en cada ciudad\n\ndays=['Monday','Wednesday','Friday']\n\ndef tracks_per_day(df):\n    for day in days:\n        filtered_day=df[df['day']==day]\n        count=filtered_day.groupby('city')['track'].count()\n        print(f'Tracks de {day}:',count)\n        print()\n\n        \nprint(tracks_per_day(df))"}, {"cell_type": "markdown", "metadata": {"id": "cC2tNrlL_Zcu"}, "source": "`Redacta brevemente tus observaciones sobre los resultados. \u00bfQu\u00e9 diferencias notaste entre Springfield y Shelbyville? \u00bfA qu\u00e9 podr\u00edan deberse esas diferencias?`"}, {"cell_type": "markdown", "metadata": {"id": "Kjb4vX38DC3I"}, "source": "Etapa 3.2. Escribe tus observaciones aqu\u00ed.\n\n-No importa el d\u00eda, en Springfield se escucha m\u00e1s m\u00fasica que en Shelbyville\n-No importa la ciudad, se escuchan m\u00e1s tracks hacia el inicio y final de la semana\n-La diferencia puede deberse a la cantidad de poblaci\u00f3n"}, {"cell_type": "markdown", "metadata": {"id": "dzli3w8o_Zcu"}, "source": "Etapa 3.3.\n1. Agrupa los datos por d\u00eda de la semana y cuenta cu\u00e1ntas canciones se reprodujeron los lunes, mi\u00e9rcoles y viernes.\n\n2. Utiliza el mismo m\u00e9todo de conteo que antes, pero ahora cambia la columna de agrupaci\u00f3n para enfocarte en el d\u00eda.\n\n3. Esto te permitir\u00e1 identificar posibles patrones de escucha seg\u00fan el d\u00eda de la semana.\n"}, {"cell_type": "code", "execution_count": 31, "metadata": {"id": "uZMKjiJz_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Tracks de Monday: day\nMonday    21354\nName: track, dtype: int64\n\nTracks de Wednesday: day\nWednesday    18059\nName: track, dtype: int64\n\nTracks de Friday: day\nFriday    21840\nName: track, dtype: int64\n\nNone\n"}], "source": "# Calcula las canciones reproducidas en cada uno de los tres d\u00edas\n\n\ndays=['Monday','Wednesday','Friday']\n\ndef tracks_per_day(df):\n    for day in days:\n        filtered_day=df[df['day']==day]\n        count=filtered_day.groupby('day')['track'].count()\n        print(f'Tracks de {day}:',count)\n        print()\n\n        \nprint(tracks_per_day(df))\n"}, {"cell_type": "markdown", "metadata": {"id": "t_Qx-3NewAnK"}, "source": "`Describe brevemente qu\u00e9 observaste al comparar los lunes, mi\u00e9rcoles y viernes. \u00bfHubo alg\u00fan d\u00eda con menos actividad? \u00bfCambian las conclusiones si analizas cada ciudad por separado?`"}, {"cell_type": "markdown", "metadata": {"id": "q537Zl8oDNfH"}, "source": "Etapa 3.4. Escribe tus observaciones aqu\u00ed.\n\nA mitad de semana se escucha menos m\u00fasica respecto al inicio y final de, seguramente por el rush del fin de semana. El viernes es el d\u00eda que m\u00e1s m\u00fasica se escucha, probablemente porque los viernes hay menos carga de trabajo o, incluso, se trabaja s\u00f3lo medio d\u00eda"}, {"cell_type": "markdown", "metadata": {"id": "POzs8bGa_Zcu"}, "source": "Hasta ahora has aprendido a contar entradas agrup\u00e1ndolas por un solo criterio, como la ciudad o el d\u00eda de la semana. Ahora vamos a dar un paso m\u00e1s: necesitas crear una funci\u00f3n que **cuente cu\u00e1ntas canciones se reprodujeron en una ciudad espec\u00edfica durante un d\u00eda determinado**, combinando ambos criterios de filtrado.\n\nLa funci\u00f3n se llamar\u00e1 `number_tracks()` y debe aceptar dos par\u00e1metros:\n\n- `day`: un d\u00eda de la semana (por ejemplo, `'Monday'`).\n- `city`: el nombre de una ciudad (por ejemplo, `'Springfield'`).\n\nDentro de la funci\u00f3n, deber\u00e1s aplicar un **filtrado secuencial mediante indexaci\u00f3n l\u00f3gica**: primero tendr\u00e1s que filtrar el DataFrame por el d\u00eda, y luego por la ciudad. Una vez que tengas el subconjunto de datos correcto, debes contar cu\u00e1ntas veces aparece un valor en la columna `'user_id'`. Ese n\u00famero representar\u00e1 el total de canciones reproducidas bajo esos dos criterios.\n\n"}, {"cell_type": "markdown", "metadata": {"id": "itD2P5lhEpuX"}, "source": "Etapa 3.5.\n1. Declara una funci\u00f3n llamada `number_tracks()` con dos par\u00e1metros: `day` y `city`.\n\n2. Filtra el DataFrame para conservar solo las filas donde la columna `'day'` sea igual al valor del par\u00e1metro `day`.\n\n3. A partir del resultado anterior, filtra nuevamente para conservar solo las filas donde la columna `'city'` sea igual al valor del par\u00e1metro `city`.\n\n4. Extrae la columna `'user_id'` del DataFrame filtrado y utiliza el m\u00e9todo `.count()` para contar el n\u00famero de entradas.\n\n5. Guarda ese valor en una variable y **devu\u00e9lvelo** como resultado de la funci\u00f3n.\n"}, {"cell_type": "code", "execution_count": 33, "metadata": {"id": "Nz3GdQB1_Zcu", "trusted": true}, "outputs": [], "source": "# Declara la funci\u00f3n number_tracks() con dos par\u00e1metros: day= y city=.\ndef number_tracks(day,city):\n    # Almacena las filas del DataFrame donde el valor en la columna 'day' es igual al par\u00e1metro day=\n    df_day=df[df['day']==day]\n    # Filtra las filas donde el valor en la columna 'city' es igual al par\u00e1metro city=\n    df_day_city=df_day[df_day['city']==city]\n    # Extrae la columna 'user_id' de la tabla filtrada y aplica el m\u00e9todo count()\n    track_count=df_day_city['user_id'].count()\n    # Devuelve el n\u00famero de valores de la columna 'user_id'\n    return track_count   "}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nRealizaste un gran trabajo con la definici\u00f3n de la funci\u00f3n. Como pudiste notar, el desarrollar funciones nos permiten encapsular l\u00f3gica reutilizable, evitando la repetici\u00f3n de c\u00f3digo y facilitando su uso en diferentes partes de un programa o en distintos proyectos.</div>"}, {"cell_type": "markdown", "metadata": {"id": "ytf7xFrFJQ2r"}, "source": "Etapa 3.6. Llama a `number_tracks()` seis veces, cambiando los valores de los par\u00e1metros para que puedas recuperar los datos de ambas ciudades para cada uno de los tres d\u00edas."}, {"cell_type": "code", "execution_count": 36, "metadata": {"id": "rJcRATNQ_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Tracks reproducidos en Springfield el d\u00eda Monday:  15740\n"}], "source": "# El n\u00famero de canciones reproducidas en Springfield el lunes\nday='Monday'\ncity='Springfield'\n\nprint(f'Tracks reproducidos en {city} el d\u00eda {day}: ',number_tracks(day,city))"}, {"cell_type": "code", "execution_count": 37, "metadata": {"id": "hq_ncZ5T_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Tracks reproducidos en Shelbyville el d\u00eda Monday:  5614\n"}], "source": "# El n\u00famero de canciones reproducidas en Shelbyville el lunes\nday='Monday'\ncity='Shelbyville'\n\nprint(f'Tracks reproducidos en {city} el d\u00eda {day}: ',number_tracks(day,city))"}, {"cell_type": "code", "execution_count": 38, "metadata": {"id": "_NTy2VPU_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Tracks reproducidos en Springfield el d\u00eda Wednesday:  11056\n"}], "source": "# El n\u00famero de canciones reproducidas en Springfield el mi\u00e9rcoles\nday='Wednesday'\ncity='Springfield'\n\nprint(f'Tracks reproducidos en {city} el d\u00eda {day}: ',number_tracks(day,city))"}, {"cell_type": "code", "execution_count": 40, "metadata": {"id": "j2y3TAwo_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Tracks reproducidos en Shelbyville el d\u00eda Wednesday:  7003\n"}], "source": "# El n\u00famero de canciones reproducidas en Shelbyville el mi\u00e9rcoles\nday='Wednesday'\ncity='Shelbyville'\n\nprint(f'Tracks reproducidos en {city} el d\u00eda {day}: ',number_tracks(day,city))"}, {"cell_type": "code", "execution_count": 41, "metadata": {"id": "vYDw5u_K_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Tracks reproducidos en Springfield el d\u00eda Friday:  15945\n"}], "source": "# El n\u00famero de canciones reproducidas en Springfield el viernes\nday='Friday'\ncity='Springfield'\n\nprint(f'Tracks reproducidos en {city} el d\u00eda {day}: ',number_tracks(day,city))"}, {"cell_type": "code", "execution_count": 43, "metadata": {"id": "8_yzFtW3_Zcu", "trusted": true}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Tracks reproducidos en Shelbyville el d\u00eda Friday:  5895\n"}], "source": "# El n\u00famero de canciones reproducidas en Shelbyville el viernes\nday='Friday'\ncity='Shelbyville'\n\nprint(f'Tracks reproducidos en {city} el d\u00eda {day}: ',number_tracks(day,city))"}, {"cell_type": "markdown", "metadata": {"id": "p7nFQajCVw5B"}, "source": "[Volver a Contenidos](#back)"}, {"cell_type": "markdown", "metadata": {"id": "ykKQ0N65_Zcv"}, "source": "# Conclusiones <a id='end'></a>"}, {"cell_type": "markdown", "metadata": {"id": "tjUwbHb3_Zcv"}, "source": "##Escribe tus conclusiones finales sobre la hip\u00f3tesis.\n * \u00bfLos datos apoyan la idea de que el comportamiento de los usuarios respecto a la m\u00fasica que escuchan var\u00eda seg\u00fan la ciudad y el d\u00eda de la semana?\n * Indica si la hip\u00f3tesis debe aceptarse o rechazarse, y justifica tu respuesta con base en los resultados obtenidos."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario del revisor</b> <a class=\"tocSkip\"></a>\n\nHola! Excelente trabajo. En futuros cursos vas a poder complementar estas pruebas con pruebas estadisticas por las pruebas de diferencias de medias, adem\u00e1s vas a poder explorar el desarrollo de gr\u00e1ficas que complementen este an\u00e1lisis. Por ejemplo en este caso podr\u00edamos desarrollar una gr\u00e1fica que muestre la cantidad de canciones por d\u00eda y otra que muestre la relaci\u00f3n por ciudad. Para esto puedes aplicar la funci\u00f3n que creaste para obtener la informaci\u00f3n necesaria para hacer estas gr\u00e1ficas</div>"}, {"cell_type": "markdown", "metadata": {"id": "piRc-ATKFwZ3"}, "source": "Etapa 4. Detalla aqu\u00ed tus conclusiones.\n\n1. En general, en Springfieldse escucha mucho m\u00e1s m\u00fasica que en Shelbyville\n2. E viernes es el d\u00eda que m\u00e1s m\u00fasica se escucha en ambas ciudades, probablemente porque el d\u00eda laboral es m\u00e1s corto y/o porque la gente sale a relajarse (sea en un bar, un centro nocturno, ect)\n3. Todo esto puede deberse a que la poblaci\u00f3n en Springfield es 6 veces m\u00e1s grande que la de Shelbyville."}, {"cell_type": "markdown", "metadata": {"id": "azLHu64yOIp7"}, "source": "### Nota\nEn los proyectos de investigaci\u00f3n reales, la prueba de hip\u00f3tesis estad\u00edstica es m\u00e1s precisa y cuantitativa. Tambi\u00e9n ten en cuenta que no siempre se pueden sacar conclusiones sobre una ciudad entera a partir de datos de una sola fuente.\n\nAprender\u00e1s m\u00e1s sobre la prueba de hip\u00f3tesis en el sprint de an\u00e1lisis estad\u00edstico de datos."}, {"cell_type": "markdown", "metadata": {}, "source": "<div class=\"alert alert-block alert-success\">\n<b>Comentario general</b> <a class=\"tocSkip\"></a>\n    \nCarlos,  hiciste un muy buen trabajo con el proyecto, pudiste resolver todos los ejericios de una forma adecuada y se nota que hiciste uso de todas las herramientas aprendidas. Adem\u00e1s, considero que te ayudo para aprender el uso de algunas funciones que te sirvan en los siguientes cursos. \n\nExitos en lo que viene, saludos.</div>"}, {"cell_type": "markdown", "metadata": {"id": "Ju4AHDSgV1FE"}, "source": "[Volver a Contenidos](#back)"}], "metadata": {"ExecuteTimeLog": [{"duration": 8, "start_time": "2025-04-13T22:01:37.446Z"}, {"duration": 3, "start_time": "2025-04-13T22:01:41.448Z"}, {"duration": 428, "start_time": "2025-04-13T22:01:51.616Z"}, {"duration": 2, "start_time": "2025-04-13T22:02:11.798Z"}, {"duration": 93, "start_time": "2025-04-13T22:02:42.877Z"}, {"duration": 7, "start_time": "2025-04-13T22:02:58.738Z"}, {"duration": 22, "start_time": "2025-04-13T22:03:19.171Z"}, {"duration": 172, "start_time": "2025-04-13T22:09:09.617Z"}, {"duration": 13, "start_time": "2025-04-13T22:09:17.046Z"}, {"duration": 12, "start_time": "2025-04-13T22:09:59.957Z"}, {"duration": 10, "start_time": "2025-04-13T22:10:13.784Z"}, {"duration": 12, "start_time": "2025-04-13T22:10:30.915Z"}, {"duration": 3, "start_time": "2025-04-13T22:11:05.569Z"}, {"duration": 4, "start_time": "2025-04-13T22:16:02.137Z"}, {"duration": 11, "start_time": "2025-04-13T22:16:10.383Z"}, {"duration": 3, "start_time": "2025-04-13T22:17:17.711Z"}, {"duration": 3, "start_time": "2025-04-13T22:18:17.644Z"}, {"duration": 3, "start_time": "2025-04-13T22:18:59.605Z"}, {"duration": 4, "start_time": "2025-04-13T22:23:43.779Z"}, {"duration": 192, "start_time": "2025-04-13T22:25:39.017Z"}, {"duration": 3, "start_time": "2025-04-13T22:28:25.889Z"}, {"duration": 3, "start_time": "2025-04-13T22:29:07.295Z"}, {"duration": 11, "start_time": "2025-04-13T22:30:08.381Z"}, {"duration": 26, "start_time": "2025-04-13T22:30:18.634Z"}, {"duration": 18, "start_time": "2025-04-13T22:30:30.098Z"}, {"duration": 32, "start_time": "2025-04-13T22:30:47.945Z"}, {"duration": 18, "start_time": "2025-04-13T22:31:02.378Z"}, {"duration": 19, "start_time": "2025-04-13T22:31:12.757Z"}, {"duration": 17, "start_time": "2025-04-13T22:35:27.106Z"}, {"duration": 33, "start_time": "2025-04-13T22:35:43.809Z"}, {"duration": 32, "start_time": "2025-04-13T22:36:20.970Z"}, {"duration": 34, "start_time": "2025-04-13T22:36:48.606Z"}, {"duration": 19, "start_time": "2025-04-13T22:41:23.000Z"}, {"duration": 15, "start_time": "2025-04-13T22:41:36.588Z"}, {"duration": 13, "start_time": "2025-04-13T22:42:15.220Z"}, {"duration": 16, "start_time": "2025-04-13T22:59:09.926Z"}, {"duration": 13, "start_time": "2025-04-13T22:59:15.384Z"}, {"duration": 13, "start_time": "2025-04-13T22:59:43.127Z"}, {"duration": 13, "start_time": "2025-04-13T23:00:22.282Z"}, {"duration": 3, "start_time": "2025-04-13T23:01:49.526Z"}, {"duration": 14, "start_time": "2025-04-13T23:01:54.999Z"}, {"duration": 18, "start_time": "2025-04-13T23:02:00.153Z"}, {"duration": 44, "start_time": "2025-04-13T23:02:32.243Z"}, {"duration": 11, "start_time": "2025-04-13T23:02:52.893Z"}, {"duration": 51, "start_time": "2025-04-13T23:03:06.004Z"}, {"duration": 44, "start_time": "2025-04-13T23:03:22.457Z"}, {"duration": 42, "start_time": "2025-04-13T23:04:51.175Z"}, {"duration": 5, "start_time": "2025-04-13T23:07:06.811Z"}, {"duration": 223, "start_time": "2025-04-13T23:07:41.387Z"}, {"duration": 59, "start_time": "2025-04-13T23:08:03.413Z"}, {"duration": 61, "start_time": "2025-04-13T23:08:30.790Z"}, {"duration": 44, "start_time": "2025-04-13T23:08:33.948Z"}, {"duration": 4, "start_time": "2025-04-13T23:09:22.259Z"}, {"duration": 254, "start_time": "2025-04-13T23:09:27.083Z"}, {"duration": 6, "start_time": "2025-04-13T23:10:01.675Z"}, {"duration": 3, "start_time": "2025-04-13T23:18:45.125Z"}, {"duration": 2, "start_time": "2025-04-13T23:20:43.881Z"}, {"duration": 2, "start_time": "2025-04-13T23:21:22.821Z"}, {"duration": 14, "start_time": "2025-04-13T23:21:54.762Z"}, {"duration": 5, "start_time": "2025-04-13T23:22:17.461Z"}, {"duration": 7, "start_time": "2025-04-13T23:22:24.595Z"}, {"duration": 13, "start_time": "2025-04-13T23:34:51.193Z"}, {"duration": 10, "start_time": "2025-04-13T23:35:52.524Z"}, {"duration": 14, "start_time": "2025-04-13T23:37:09.629Z"}, {"duration": 15, "start_time": "2025-04-13T23:37:12.878Z"}, {"duration": 15, "start_time": "2025-04-13T23:37:34.055Z"}, {"duration": 117, "start_time": "2025-04-13T23:38:08.560Z"}, {"duration": 5, "start_time": "2025-04-13T23:38:32.667Z"}, {"duration": 32, "start_time": "2025-04-13T23:41:47.878Z"}, {"duration": 33, "start_time": "2025-04-13T23:42:12.914Z"}, {"duration": 30, "start_time": "2025-04-13T23:47:56.014Z"}, {"duration": 29, "start_time": "2025-04-13T23:49:12.205Z"}, {"duration": 4, "start_time": "2025-04-24T17:27:34.110Z"}, {"duration": 47, "start_time": "2025-04-24T17:28:22.298Z"}, {"duration": 45, "start_time": "2025-04-24T17:28:34.361Z"}, {"duration": 43, "start_time": "2025-04-24T17:33:01.766Z"}, {"duration": 14, "start_time": "2025-04-24T17:37:05.104Z"}, {"duration": 3, "start_time": "2025-04-24T17:39:35.963Z"}, {"duration": 3, "start_time": "2025-04-24T17:39:38.579Z"}, {"duration": 3, "start_time": "2025-04-24T17:40:02.455Z"}, {"duration": 3, "start_time": "2025-04-24T19:34:51.186Z"}, {"duration": 3, "start_time": "2025-04-24T19:36:05.379Z"}, {"duration": 102, "start_time": "2025-04-24T19:37:46.732Z"}, {"duration": 42, "start_time": "2025-04-24T19:40:00.740Z"}, {"duration": 137, "start_time": "2025-04-24T19:41:06.398Z"}, {"duration": 3, "start_time": "2025-04-24T19:41:08.882Z"}, {"duration": 94, "start_time": "2025-04-24T19:41:10.527Z"}, {"duration": 7, "start_time": "2025-04-24T19:41:23.001Z"}, {"duration": 22, "start_time": "2025-04-24T19:41:27.958Z"}, {"duration": 5, "start_time": "2025-04-24T19:42:30.364Z"}, {"duration": 4, "start_time": "2025-04-24T19:42:42.531Z"}, {"duration": 4, "start_time": "2025-04-24T19:43:34.800Z"}, {"duration": 3, "start_time": "2025-04-24T19:43:37.951Z"}, {"duration": 17, "start_time": "2025-04-24T19:46:54.145Z"}, {"duration": 16, "start_time": "2025-04-24T19:47:01.437Z"}, {"duration": 44, "start_time": "2025-04-24T19:47:28.278Z"}, {"duration": 314, "start_time": "2025-04-24T19:49:56.705Z"}, {"duration": 41, "start_time": "2025-04-24T19:50:23.883Z"}, {"duration": 45, "start_time": "2025-04-24T19:50:32.105Z"}, {"duration": 45, "start_time": "2025-04-24T19:50:38.597Z"}, {"duration": 6, "start_time": "2025-04-24T19:50:55.757Z"}, {"duration": 3, "start_time": "2025-04-24T19:54:58.375Z"}, {"duration": 9, "start_time": "2025-04-24T19:55:20.834Z"}, {"duration": 30, "start_time": "2025-04-24T19:57:53.876Z"}, {"duration": 10, "start_time": "2025-04-24T21:13:17.812Z"}, {"duration": 30, "start_time": "2025-04-24T21:13:35.673Z"}, {"duration": 54, "start_time": "2025-04-24T21:15:21.047Z"}, {"duration": 54, "start_time": "2025-04-24T21:15:55.393Z"}, {"duration": 51, "start_time": "2025-04-24T21:16:06.029Z"}, {"duration": 28, "start_time": "2025-04-24T21:16:21.075Z"}, {"duration": 174, "start_time": "2025-04-25T17:27:22.579Z"}, {"duration": 12, "start_time": "2025-04-25T17:27:25.648Z"}, {"duration": 15, "start_time": "2025-04-25T17:27:36.214Z"}, {"duration": 15, "start_time": "2025-04-25T17:27:46.345Z"}, {"duration": 303, "start_time": "2025-04-25T17:27:48.971Z"}, {"duration": 395, "start_time": "2025-04-25T17:27:50.608Z"}, {"duration": 454, "start_time": "2025-04-25T17:28:02.120Z"}, {"duration": 45, "start_time": "2025-04-25T17:28:16.530Z"}, {"duration": 2, "start_time": "2025-04-25T17:28:55.751Z"}, {"duration": 91, "start_time": "2025-04-25T17:28:57.405Z"}, {"duration": 7, "start_time": "2025-04-25T17:28:58.980Z"}, {"duration": 22, "start_time": "2025-04-25T17:29:02.489Z"}, {"duration": 3, "start_time": "2025-04-25T17:29:09.009Z"}, {"duration": 4, "start_time": "2025-04-25T17:29:11.901Z"}, {"duration": 5, "start_time": "2025-04-25T17:29:14.701Z"}, {"duration": 4, "start_time": "2025-04-25T17:29:17.070Z"}, {"duration": 3, "start_time": "2025-04-25T17:29:19.311Z"}, {"duration": 37, "start_time": "2025-04-25T17:29:21.386Z"}, {"duration": 11, "start_time": "2025-04-25T17:29:28.972Z"}, {"duration": 18, "start_time": "2025-04-25T17:29:31.104Z"}, {"duration": 45, "start_time": "2025-04-25T17:29:34.184Z"}, {"duration": 49, "start_time": "2025-04-25T17:29:36.736Z"}, {"duration": 43, "start_time": "2025-04-25T17:29:38.369Z"}, {"duration": 6, "start_time": "2025-04-25T17:29:40.926Z"}, {"duration": 3, "start_time": "2025-04-25T17:29:46.243Z"}, {"duration": 10, "start_time": "2025-04-25T17:29:48.087Z"}, {"duration": 7, "start_time": "2025-04-25T17:29:51.728Z"}, {"duration": 6, "start_time": "2025-04-25T17:29:57.308Z"}, {"duration": 32, "start_time": "2025-04-25T17:29:59.747Z"}, {"duration": 31, "start_time": "2025-04-25T17:30:03.369Z"}, {"duration": 31, "start_time": "2025-04-25T17:30:33.349Z"}, {"duration": 3, "start_time": "2025-04-25T17:49:57.610Z"}, {"duration": 3, "start_time": "2025-04-25T17:50:56.270Z"}, {"duration": 12, "start_time": "2025-04-25T17:51:35.117Z"}, {"duration": 14, "start_time": "2025-04-25T17:52:54.736Z"}, {"duration": 14, "start_time": "2025-04-25T17:53:01.508Z"}, {"duration": 13, "start_time": "2025-04-25T17:53:46.102Z"}, {"duration": 14, "start_time": "2025-04-25T17:54:27.293Z"}, {"duration": 2, "start_time": "2025-04-25T17:54:38.531Z"}, {"duration": 12, "start_time": "2025-04-25T17:54:52.566Z"}, {"duration": 17, "start_time": "2025-04-25T17:55:08.944Z"}, {"duration": 18, "start_time": "2025-04-25T17:56:32.677Z"}, {"duration": 12, "start_time": "2025-04-25T17:59:18.266Z"}], "colab": {"collapsed_sections": ["E0vqbgi9ay0H", "VUC88oWjTJw2"], "provenance": []}, "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.19"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": true, "sideBar": true, "skip_h1_title": true, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 1}